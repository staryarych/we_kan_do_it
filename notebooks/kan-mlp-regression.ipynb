{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30699,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":5,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install wandb \n!pip install python-dotenv","metadata":{"execution":{"iopub.status.busy":"2024-05-28T20:42:53.892951Z","iopub.execute_input":"2024-05-28T20:42:53.893316Z","iopub.status.idle":"2024-05-28T20:43:19.391032Z","shell.execute_reply.started":"2024-05-28T20:42:53.893286Z","shell.execute_reply":"2024-05-28T20:43:19.389987Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Requirement already satisfied: wandb in /opt/conda/lib/python3.10/site-packages (0.16.6)\nRequirement already satisfied: Click!=8.0.0,>=7.1 in /opt/conda/lib/python3.10/site-packages (from wandb) (8.1.7)\nRequirement already satisfied: GitPython!=3.1.29,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (3.1.41)\nRequirement already satisfied: requests<3,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (2.31.0)\nRequirement already satisfied: psutil>=5.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (5.9.3)\nRequirement already satisfied: sentry-sdk>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (1.45.0)\nRequirement already satisfied: docker-pycreds>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (0.4.0)\nRequirement already satisfied: PyYAML in /opt/conda/lib/python3.10/site-packages (from wandb) (6.0.1)\nRequirement already satisfied: setproctitle in /opt/conda/lib/python3.10/site-packages (from wandb) (1.3.3)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from wandb) (69.0.3)\nRequirement already satisfied: appdirs>=1.4.3 in /opt/conda/lib/python3.10/site-packages (from wandb) (1.4.4)\nRequirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (3.20.3)\nRequirement already satisfied: six>=1.4.0 in /opt/conda/lib/python3.10/site-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\nRequirement already satisfied: gitdb<5,>=4.0.1 in /opt/conda/lib/python3.10/site-packages (from GitPython!=3.1.29,>=1.0.0->wandb) (4.0.11)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (2024.2.2)\nRequirement already satisfied: smmap<6,>=3.0.1 in /opt/conda/lib/python3.10/site-packages (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb) (5.0.1)\nRequirement already satisfied: python-dotenv in /opt/conda/lib/python3.10/site-packages (1.0.0)\n","output_type":"stream"}]},{"cell_type":"code","source":"import os\nimport math\nimport random\n\nfrom dotenv import load_dotenv, find_dotenv\n\nimport torch\nimport torch.nn as nn\nfrom torch.nn import functional as F\nfrom torch.utils.data import DataLoader\nfrom torchvision import transforms\nimport torch.nn.init as init\n\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\nimport wandb\n\n__ENV_FILE = find_dotenv(f'{os.getenv(\"ENV\", \"var\")}.env')\nload_dotenv(__ENV_FILE)","metadata":{"execution":{"iopub.status.busy":"2024-05-28T20:43:19.393380Z","iopub.execute_input":"2024-05-28T20:43:19.394169Z","iopub.status.idle":"2024-05-28T20:43:26.551407Z","shell.execute_reply.started":"2024-05-28T20:43:19.394130Z","shell.execute_reply":"2024-05-28T20:43:26.550549Z"},"trusted":true},"execution_count":2,"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"False"},"metadata":{}}]},{"cell_type":"code","source":"def seed_all(seed_value):\n    random.seed(seed_value)\n    np.random.seed(seed_value)\n    torch.manual_seed(seed_value)\n    if torch.cuda.is_available():\n        torch.cuda.manual_seed(seed_value)\n        torch.cuda.manual_seed_all(seed_value)","metadata":{"execution":{"iopub.status.busy":"2024-05-28T20:43:26.557194Z","iopub.execute_input":"2024-05-28T20:43:26.557792Z","iopub.status.idle":"2024-05-28T20:43:26.563496Z","shell.execute_reply.started":"2024-05-28T20:43:26.557757Z","shell.execute_reply":"2024-05-28T20:43:26.562385Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"# Models definitions","metadata":{}},{"cell_type":"code","source":"class MLP(nn.Module):\n    def __init__(self, input_size, hidden_size, output_size):\n        super(MLP, self).__init__()\n        self.fc1 = nn.Linear(input_size, hidden_size)\n        self.relu = nn.ReLU()\n        self.fc2 = nn.Linear(hidden_size, output_size)\n\n        init.kaiming_uniform_(self.fc1.weight, nonlinearity='relu')\n        init.kaiming_uniform_(self.fc2.weight, nonlinearity='relu')\n\n    def forward(self, x):\n        out = self.fc1(x)\n        out = self.relu(out)\n        out = self.fc2(out)\n        \n        return out","metadata":{"execution":{"iopub.status.busy":"2024-05-28T20:43:26.564391Z","iopub.execute_input":"2024-05-28T20:43:26.564642Z","iopub.status.idle":"2024-05-28T20:43:26.575256Z","shell.execute_reply.started":"2024-05-28T20:43:26.564618Z","shell.execute_reply":"2024-05-28T20:43:26.574407Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"class KANLinear(torch.nn.Module):\n    def __init__(\n        self,\n        in_features,\n        out_features,\n        grid_size=5,\n        spline_order=3,\n        scale_noise=0.1,\n        scale_base=1.0,\n        scale_spline=1.0,\n        enable_standalone_scale_spline=True,\n        base_activation=torch.nn.SiLU,\n        grid_eps=0.02,\n        grid_range=[-1, 1],\n    ):\n        super(KANLinear, self).__init__()\n        self.in_features = in_features\n        self.out_features = out_features\n        self.grid_size = grid_size\n        self.spline_order = spline_order\n\n        h = (grid_range[1] - grid_range[0]) / grid_size\n        grid = (\n            (\n                torch.arange(-spline_order, grid_size + spline_order + 1) * h\n                + grid_range[0]\n            )\n            .expand(in_features, -1)\n            .contiguous()\n        )\n        self.register_buffer(\"grid\", grid)\n\n        self.base_weight = torch.nn.Parameter(torch.Tensor(out_features, in_features))\n        self.spline_weight = torch.nn.Parameter(\n            torch.Tensor(out_features, in_features, grid_size + spline_order)\n        )\n        if enable_standalone_scale_spline:\n            self.spline_scaler = torch.nn.Parameter(\n                torch.Tensor(out_features, in_features)\n            )\n\n        self.scale_noise = scale_noise\n        self.scale_base = scale_base\n        self.scale_spline = scale_spline\n        self.enable_standalone_scale_spline = enable_standalone_scale_spline\n        self.base_activation = base_activation()\n        self.grid_eps = grid_eps\n\n        self.reset_parameters()\n\n    def reset_parameters(self):\n        torch.nn.init.kaiming_uniform_(self.base_weight, a=math.sqrt(5) * self.scale_base)\n        with torch.no_grad():\n            noise = (\n                (\n                    torch.rand(self.grid_size + 1, self.in_features, self.out_features)\n                    - 1 / 2\n                )\n                * self.scale_noise\n                / self.grid_size\n            )\n            self.spline_weight.data.copy_(\n                (self.scale_spline if not self.enable_standalone_scale_spline else 1.0)\n                * self.curve2coeff(\n                    self.grid.T[self.spline_order : -self.spline_order],\n                    noise,\n                )\n            )\n            if self.enable_standalone_scale_spline:\n                # torch.nn.init.constant_(self.spline_scaler, self.scale_spline)\n                torch.nn.init.kaiming_uniform_(self.spline_scaler, a=math.sqrt(5) * self.scale_spline)\n\n    def b_splines(self, x: torch.Tensor):\n        \"\"\"\n        Compute the B-spline bases for the given input tensor.\n\n        Args:\n            x (torch.Tensor): Input tensor of shape (batch_size, in_features).\n\n        Returns:\n            torch.Tensor: B-spline bases tensor of shape (batch_size, in_features, grid_size + spline_order).\n        \"\"\"\n        assert x.dim() == 2 and x.size(1) == self.in_features\n\n        grid: torch.Tensor = (\n            self.grid\n        )  # (in_features, grid_size + 2 * spline_order + 1)\n        x = x.unsqueeze(-1)\n        bases = ((x >= grid[:, :-1]) & (x < grid[:, 1:])).to(x.dtype)\n        for k in range(1, self.spline_order + 1):\n            bases = (\n                (x - grid[:, : -(k + 1)])\n                / (grid[:, k:-1] - grid[:, : -(k + 1)])\n                * bases[:, :, :-1]\n            ) + (\n                (grid[:, k + 1 :] - x)\n                / (grid[:, k + 1 :] - grid[:, 1:(-k)])\n                * bases[:, :, 1:]\n            )\n\n        assert bases.size() == (\n            x.size(0),\n            self.in_features,\n            self.grid_size + self.spline_order,\n        )\n        return bases.contiguous()\n\n    def curve2coeff(self, x: torch.Tensor, y: torch.Tensor):\n        \"\"\"\n        Compute the coefficients of the curve that interpolates the given points.\n\n        Args:\n            x (torch.Tensor): Input tensor of shape (batch_size, in_features).\n            y (torch.Tensor): Output tensor of shape (batch_size, in_features, out_features).\n\n        Returns:\n            torch.Tensor: Coefficients tensor of shape (out_features, in_features, grid_size + spline_order).\n        \"\"\"\n        assert x.dim() == 2 and x.size(1) == self.in_features\n        assert y.size() == (x.size(0), self.in_features, self.out_features)\n\n        A = self.b_splines(x).transpose(\n            0, 1\n        )  # (in_features, batch_size, grid_size + spline_order)\n        B = y.transpose(0, 1)  # (in_features, batch_size, out_features)\n        solution = torch.linalg.lstsq(\n            A, B\n        ).solution  # (in_features, grid_size + spline_order, out_features)\n        result = solution.permute(\n            2, 0, 1\n        )  # (out_features, in_features, grid_size + spline_order)\n\n        assert result.size() == (\n            self.out_features,\n            self.in_features,\n            self.grid_size + self.spline_order,\n        )\n        return result.contiguous()\n\n    @property\n    def scaled_spline_weight(self):\n        return self.spline_weight * (\n            self.spline_scaler.unsqueeze(-1)\n            if self.enable_standalone_scale_spline\n            else 1.0\n        )\n\n    def forward(self, x: torch.Tensor):\n        assert x.size(-1) == self.in_features\n        original_shape = x.shape\n        x = x.view(-1, self.in_features)\n\n        base_output = F.linear(self.base_activation(x), self.base_weight)\n        spline_output = F.linear(\n            self.b_splines(x).view(x.size(0), -1),\n            self.scaled_spline_weight.view(self.out_features, -1),\n        )\n        output = base_output + spline_output\n        \n        output = output.view(*original_shape[:-1], self.out_features)\n        return output\n\n    @torch.no_grad()\n    def update_grid(self, x: torch.Tensor, margin=0.01):\n        assert x.dim() == 2 and x.size(1) == self.in_features\n        batch = x.size(0)\n\n        splines = self.b_splines(x)  # (batch, in, coeff)\n        splines = splines.permute(1, 0, 2)  # (in, batch, coeff)\n        orig_coeff = self.scaled_spline_weight  # (out, in, coeff)\n        orig_coeff = orig_coeff.permute(1, 2, 0)  # (in, coeff, out)\n        unreduced_spline_output = torch.bmm(splines, orig_coeff)  # (in, batch, out)\n        unreduced_spline_output = unreduced_spline_output.permute(\n            1, 0, 2\n        )  # (batch, in, out)\n\n        # sort each channel individually to collect data distribution\n        x_sorted = torch.sort(x, dim=0)[0]\n        grid_adaptive = x_sorted[\n            torch.linspace(\n                0, batch - 1, self.grid_size + 1, dtype=torch.int64, device=x.device\n            )\n        ]\n\n        uniform_step = (x_sorted[-1] - x_sorted[0] + 2 * margin) / self.grid_size\n        grid_uniform = (\n            torch.arange(\n                self.grid_size + 1, dtype=torch.float32, device=x.device\n            ).unsqueeze(1)\n            * uniform_step\n            + x_sorted[0]\n            - margin\n        )\n\n        grid = self.grid_eps * grid_uniform + (1 - self.grid_eps) * grid_adaptive\n        grid = torch.concatenate(\n            [\n                grid[:1]\n                - uniform_step\n                * torch.arange(self.spline_order, 0, -1, device=x.device).unsqueeze(1),\n                grid,\n                grid[-1:]\n                + uniform_step\n                * torch.arange(1, self.spline_order + 1, device=x.device).unsqueeze(1),\n            ],\n            dim=0,\n        )\n\n        self.grid.copy_(grid.T)\n        self.spline_weight.data.copy_(self.curve2coeff(x, unreduced_spline_output))\n\n    def regularization_loss(self, regularize_activation=1.0, regularize_entropy=1.0):\n        \"\"\"\n        Compute the regularization loss.\n\n        This is a dumb simulation of the original L1 regularization as stated in the\n        paper, since the original one requires computing absolutes and entropy from the\n        expanded (batch, in_features, out_features) intermediate tensor, which is hidden\n        behind the F.linear function if we want an memory efficient implementation.\n\n        The L1 regularization is now computed as mean absolute value of the spline\n        weights. The authors implementation also includes this term in addition to the\n        sample-based regularization.\n        \"\"\"\n        l1_fake = self.spline_weight.abs().mean(-1)\n        regularization_loss_activation = l1_fake.sum()\n        p = l1_fake / regularization_loss_activation\n        regularization_loss_entropy = -torch.sum(p * p.log())\n        return (\n            regularize_activation * regularization_loss_activation\n            + regularize_entropy * regularization_loss_entropy\n        )\n\n\nclass KAN(torch.nn.Module):\n    def __init__(\n        self,\n        layers_hidden,\n        grid_size=5,\n        spline_order=3,\n        scale_noise=0.1,\n        scale_base=1.0,\n        scale_spline=1.0,\n        base_activation=torch.nn.SiLU,\n        grid_eps=0.02,\n        grid_range=[-1, 1],\n    ):\n        super(KAN, self).__init__()\n        self.grid_size = grid_size\n        self.spline_order = spline_order\n\n        self.layers = torch.nn.ModuleList()\n        for in_features, out_features in zip(layers_hidden, layers_hidden[1:]):\n            self.layers.append(\n                KANLinear(\n                    in_features,\n                    out_features,\n                    grid_size=grid_size,\n                    spline_order=spline_order,\n                    scale_noise=scale_noise,\n                    scale_base=scale_base,\n                    scale_spline=scale_spline,\n                    base_activation=base_activation,\n                    grid_eps=grid_eps,\n                    grid_range=grid_range,\n                )\n            )\n\n    def forward(self, x: torch.Tensor, update_grid=False):\n        for layer in self.layers:\n            if update_grid:\n                layer.update_grid(x)\n            x = layer(x)\n        return x\n\n    def regularization_loss(self, regularize_activation=1.0, regularize_entropy=1.0):\n        return sum(\n            layer.regularization_loss(regularize_activation, regularize_entropy)\n            for layer in self.layers\n        )","metadata":{"execution":{"iopub.status.busy":"2024-05-28T20:43:26.576728Z","iopub.execute_input":"2024-05-28T20:43:26.577316Z","iopub.status.idle":"2024-05-28T20:43:26.620180Z","shell.execute_reply.started":"2024-05-28T20:43:26.577283Z","shell.execute_reply":"2024-05-28T20:43:26.619195Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"# Trainning","metadata":{}},{"cell_type":"markdown","source":"## Prepare Boston dataset","metadata":{}},{"cell_type":"code","source":"from sklearn.datasets import fetch_california_housing\nimport numpy as np\nhousing = fetch_california_housing(download_if_missing=True)","metadata":{"execution":{"iopub.status.busy":"2024-05-28T20:43:26.621351Z","iopub.execute_input":"2024-05-28T20:43:26.621717Z","iopub.status.idle":"2024-05-28T20:43:29.990299Z","shell.execute_reply.started":"2024-05-28T20:43:26.621682Z","shell.execute_reply":"2024-05-28T20:43:29.989322Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"from torch.utils.data import Dataset\n\nclass HousingDataset(Dataset):\n    def __init__(self, bunch):\n        self.bunch = bunch\n        \n    def __getitem__(self, index):\n        features = torch.from_numpy(self.bunch[\"data\"][index]).float()\n        target = torch.from_numpy(np.asarray(self.bunch[\"target\"][index])).float()\n        return features, target\n        \n    def __len__(self):\n        return len(self.bunch)","metadata":{"execution":{"iopub.status.busy":"2024-05-28T20:43:29.991482Z","iopub.execute_input":"2024-05-28T20:43:29.991748Z","iopub.status.idle":"2024-05-28T20:43:29.999061Z","shell.execute_reply.started":"2024-05-28T20:43:29.991724Z","shell.execute_reply":"2024-05-28T20:43:29.998170Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"dataset = HousingDataset(housing)","metadata":{"execution":{"iopub.status.busy":"2024-05-28T20:43:30.000116Z","iopub.execute_input":"2024-05-28T20:43:30.000369Z","iopub.status.idle":"2024-05-28T20:43:30.008373Z","shell.execute_reply.started":"2024-05-28T20:43:30.000346Z","shell.execute_reply":"2024-05-28T20:43:30.007447Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"TRAIN_SPLIT = 0.8\nVALIDATION_SPLIT = 0.1\nTEST_SPLIT = 0.1\nBATCH_SIZE = 20\nseed_all(42)\n\nshallow_dataset= torch.utils.data.Subset(dataset, [i for i in range(10)])\ntrain_set, validation_set, test_set = torch.utils.data.random_split(\n    shallow_dataset, [TRAIN_SPLIT, VALIDATION_SPLIT, TEST_SPLIT]\n)\n\ntrain_loader = DataLoader(train_set, batch_size=BATCH_SIZE)\nvalidation_loader = DataLoader(validation_set, batch_size=BATCH_SIZE)\ntest_loader = DataLoader(test_set, batch_size=BATCH_SIZE)","metadata":{"execution":{"iopub.status.busy":"2024-05-28T21:07:45.312760Z","iopub.execute_input":"2024-05-28T21:07:45.313761Z","iopub.status.idle":"2024-05-28T21:07:45.320835Z","shell.execute_reply.started":"2024-05-28T21:07:45.313722Z","shell.execute_reply":"2024-05-28T21:07:45.319760Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"INPUT_SIZE = 8\nHIDDEN_SIZE = 128\nOUTPUT_SIZE = 1\nNUM_EPOCHS = 300\nLEARNING_RATE = 1E-3\nDEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'","metadata":{"execution":{"iopub.status.busy":"2024-05-28T21:07:45.685654Z","iopub.execute_input":"2024-05-28T21:07:45.686587Z","iopub.status.idle":"2024-05-28T21:07:45.692040Z","shell.execute_reply.started":"2024-05-28T21:07:45.686547Z","shell.execute_reply":"2024-05-28T21:07:45.690765Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"markdown","source":"## MLP","metadata":{}},{"cell_type":"code","source":"# wandb config\n\n# WANDB_API_KEY = os.environ.get('WANDB_API_KEY')\nWANDB_API_KEY=\"5b2ceb8edc2e4f40870207591750b6a38db675fc\"\nwandb.login(key=WANDB_API_KEY)\n\nrun = wandb.init(\n    project=\"MLP_REGRESSION\",\n    config={\n        \"learning_rate\": LEARNING_RATE,\n        \"epochs\": NUM_EPOCHS,\n        \"entity\": \"staff\",\n        \"group\": \"creating_kan\",\n        \"name\": \"KAN\",\n    },\n)","metadata":{"execution":{"iopub.status.busy":"2024-05-28T21:12:07.477653Z","iopub.execute_input":"2024-05-28T21:12:07.478349Z","iopub.status.idle":"2024-05-28T21:12:25.255250Z","shell.execute_reply.started":"2024-05-28T21:12:07.478314Z","shell.execute_reply":"2024-05-28T21:12:25.254031Z"},"trusted":true},"execution_count":37,"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.17.0 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.16.6"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240528_211207-lo4ghrq0</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/pykan/MLP_REGRESSION/runs/lo4ghrq0' target=\"_blank\">jumping-cosmos-17</a></strong> to <a href='https://wandb.ai/pykan/MLP_REGRESSION' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/pykan/MLP_REGRESSION' target=\"_blank\">https://wandb.ai/pykan/MLP_REGRESSION</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/pykan/MLP_REGRESSION/runs/lo4ghrq0' target=\"_blank\">https://wandb.ai/pykan/MLP_REGRESSION/runs/lo4ghrq0</a>"},"metadata":{}}]},{"cell_type":"code","source":"model = MLP(INPUT_SIZE, HIDDEN_SIZE, OUTPUT_SIZE)\nmodel = model.to(DEVICE)\n\ncriterion = nn.MSELoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\ndataloader = train_loader\n\nwandb.watch(model, log=\"all\")\nwandb.log({'M_parameters': sum(p.numel() for p in model.parameters())/1e6})\nfor epoch in range(NUM_EPOCHS):\n    for batch, labels in dataloader:\n        for inputs, label in zip(batch, labels):\n            inputs, label = inputs.to(DEVICE), (label.view(-1,)).to(DEVICE)\n            pred = model(inputs)\n            loss = criterion(pred, label)\n            \n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n            wandb.log({\"loss\": loss})\n # validation\n    model.eval()\n    ep_maes, ep_mses = torch.zeros(1),  torch.zeros(1)\n    \n    for inputs, labels in validation_loader:        \n        inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n        \n        inputs = inputs.view(inputs.shape[0], -1)\n        preds = model(inputs)\n        \n        y_true = labels.detach().cpu().numpy()\n        y_pred = preds.view(-1,).detach().cpu().numpy()\n        \n        mae = mean_absolute_error(y_true, y_pred)\n        mse = mean_squared_error(y_true, y_pred)\n        \n        ep_maes += mae\n        ep_mses += mse\n        \n    ep_maes /= len(validation_loader)\n    ep_mses /= len(validation_loader)\n    \n    wandb.log({\"validation_mae\": ep_maes})\n    wandb.log({\"validation_mse\": ep_mses})\n            \nmodel.eval()\nfor epoch in range(1):\n    ep_maes, ep_mses = torch.zeros(1),  torch.zeros(1)\n    \n    for inputs, labels in test_loader:        \n        inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n        \n        inputs = inputs.view(inputs.shape[0], -1)\n        preds = model(inputs)\n        \n        y_true = labels.detach().cpu().numpy()\n        y_pred = preds.detach().cpu().numpy()\n        \n        mae = mean_absolute_error(y_true, y_pred)\n        mse = mean_squared_error(y_true, y_pred)\n        \n        ep_maes += mae\n        ep_mses += mse\n        \n    ep_maes /= len(validation_loader)\n    ep_mses /= len(validation_loader)\n    \n    wandb.log({\"test_mae\": ep_maes})\n    wandb.log({\"test_mse\": ep_mses})\n        \nwandb.finish()","metadata":{"execution":{"iopub.status.busy":"2024-05-28T21:12:25.257143Z","iopub.execute_input":"2024-05-28T21:12:25.257431Z","iopub.status.idle":"2024-05-28T21:12:29.606659Z","shell.execute_reply.started":"2024-05-28T21:12:25.257404Z","shell.execute_reply":"2024-05-28T21:12:29.605957Z"},"trusted":true},"execution_count":38,"outputs":[{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='0.018 MB of 0.018 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>M_parameters</td><td>▁</td></tr><tr><td>loss</td><td>▂█▁▁▁▁▁▁▁▂▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>test_mae</td><td>▁</td></tr><tr><td>test_mse</td><td>▁</td></tr><tr><td>validation_mae</td><td>█▂▃▁▃▃▂▁▂▂</td></tr><tr><td>validation_mse</td><td>█▁▂▁▂▂▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>M_parameters</td><td>0.00128</td></tr><tr><td>loss</td><td>162.83492</td></tr><tr><td>test_mae</td><td>12.07905</td></tr><tr><td>test_mse</td><td>145.90355</td></tr><tr><td>validation_mae</td><td>9.22524</td></tr><tr><td>validation_mse</td><td>85.10498</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">jumping-cosmos-17</strong> at: <a href='https://wandb.ai/pykan/MLP_REGRESSION/runs/lo4ghrq0' target=\"_blank\">https://wandb.ai/pykan/MLP_REGRESSION/runs/lo4ghrq0</a><br/> View project at: <a href='https://wandb.ai/pykan/MLP_REGRESSION' target=\"_blank\">https://wandb.ai/pykan/MLP_REGRESSION</a><br/>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20240528_211207-lo4ghrq0/logs</code>"},"metadata":{}}]},{"cell_type":"markdown","source":"# KAN","metadata":{}},{"cell_type":"code","source":"# wandb config\n\n# WANDB_API_KEY = os.environ.get('WANDB_API_KEY')\nWANDB_API_KEY=\"5b2ceb8edc2e4f40870207591750b6a38db675fc\"\nwandb.login(key=WANDB_API_KEY)\n\nrun = wandb.init(\n    project=\"KAN_REGRESSION\",\n    config={\n        \"learning_rate\": LEARNING_RATE,\n        \"epochs\": NUM_EPOCHS,\n        \"entity\": \"staff\",\n        \"group\": \"creating_kan\",\n        \"name\": \"KAN\",\n    },\n)","metadata":{"execution":{"iopub.status.busy":"2024-05-28T21:12:29.607649Z","iopub.execute_input":"2024-05-28T21:12:29.607917Z","iopub.status.idle":"2024-05-28T21:12:47.633760Z","shell.execute_reply.started":"2024-05-28T21:12:29.607892Z","shell.execute_reply":"2024-05-28T21:12:47.632797Z"},"trusted":true},"execution_count":39,"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.17.0 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.16.6"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240528_211230-izy4wlj6</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/pykan/KAN_REGRESSION/runs/izy4wlj6' target=\"_blank\">tough-disco-15</a></strong> to <a href='https://wandb.ai/pykan/KAN_REGRESSION' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/pykan/KAN_REGRESSION' target=\"_blank\">https://wandb.ai/pykan/KAN_REGRESSION</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/pykan/KAN_REGRESSION/runs/izy4wlj6' target=\"_blank\">https://wandb.ai/pykan/KAN_REGRESSION/runs/izy4wlj6</a>"},"metadata":{}}]},{"cell_type":"code","source":"model = KAN([INPUT_SIZE,OUTPUT_SIZE])\nmodel = model.to(DEVICE)\n\ncriterion = nn.MSELoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\ndataloader = train_loader\n\nwandb.watch(model, log=\"all\")\nwandb.log({'M_parameters': sum(p.numel() for p in model.parameters())/1e6})\nfor epoch in range(NUM_EPOCHS):\n    for batch, labels in dataloader:\n        for inputs, label in zip(batch, labels):\n            inputs, label = inputs.to(DEVICE), (label.view(-1,)).to(DEVICE)\n            pred = model(inputs)\n            loss = criterion(pred, label)\n            \n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n            wandb.log({\"loss\": loss})\n    \n    # validation\n    model.eval()\n    ep_maes, ep_mses, ep_r2s = torch.zeros(1),  torch.zeros(1), torch.zeros(1)\n    \n    for inputs, labels in validation_loader:        \n        inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n        \n        inputs = inputs.view(inputs.shape[0], -1)\n        preds = model(inputs)\n        \n        y_true = labels.detach().cpu().numpy()\n        y_pred = preds.detach().cpu().numpy()\n        \n        mae = mean_absolute_error(y_true, y_pred)\n        mse = mean_squared_error(y_true, y_pred)\n        \n        \n        ep_maes += mae\n        ep_mses += mse\n        \n        \n    ep_maes /= len(validation_loader)\n    ep_mses /= len(validation_loader)\n        \n    wandb.log({\"validation_mae\": ep_maes})\n    wandb.log({\"validation_mse\": ep_mses})\n               \nmodel.eval()\nfor epoch in range(1):\n    ep_maes, ep_mses= torch.zeros(1),  torch.zeros(1)\n    \n    for inputs, labels in test_loader:        \n        inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n        \n        inputs = inputs.view(inputs.shape[0], -1)\n        preds = model(inputs)\n        \n        y_true = labels.detach().cpu().numpy()\n        y_pred = preds.detach().cpu().numpy()\n        \n        mae = mean_absolute_error(y_true, y_pred)\n        mse = mean_squared_error(y_true, y_pred)\n        \n        ep_maes += mae\n        ep_mses += mse\n        \n    ep_maes /= len(validation_loader)\n    ep_mses /= len(validation_loader)\n    \n    wandb.log({\"test_mae\": ep_maes})\n    wandb.log({\"test_mse\": ep_mses})\n        \nwandb.finish()","metadata":{"execution":{"iopub.status.busy":"2024-05-28T21:12:47.635764Z","iopub.execute_input":"2024-05-28T21:12:47.636452Z","iopub.status.idle":"2024-05-28T21:12:51.864100Z","shell.execute_reply.started":"2024-05-28T21:12:47.636411Z","shell.execute_reply":"2024-05-28T21:12:51.863370Z"},"trusted":true},"execution_count":40,"outputs":[{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='0.018 MB of 0.018 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>M_parameters</td><td>▁</td></tr><tr><td>loss</td><td>▅█▄▅▃▁▂▃▂▃▁▃▁▃▁▃▂▂▂▃▂▁▂▃▂▁▂▃▂▁▁▃▁▁▁▃▁▁▁▁</td></tr><tr><td>test_mae</td><td>▁</td></tr><tr><td>test_mse</td><td>▁</td></tr><tr><td>validation_mae</td><td>█▃▁▂▃▃▂▂▁▁</td></tr><tr><td>validation_mse</td><td>█▂▁▂▂▃▂▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>M_parameters</td><td>8e-05</td></tr><tr><td>loss</td><td>8.68824</td></tr><tr><td>test_mae</td><td>0.85471</td></tr><tr><td>test_mse</td><td>0.73053</td></tr><tr><td>validation_mae</td><td>3.26845</td></tr><tr><td>validation_mse</td><td>10.68279</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">tough-disco-15</strong> at: <a href='https://wandb.ai/pykan/KAN_REGRESSION/runs/izy4wlj6' target=\"_blank\">https://wandb.ai/pykan/KAN_REGRESSION/runs/izy4wlj6</a><br/> View project at: <a href='https://wandb.ai/pykan/KAN_REGRESSION' target=\"_blank\">https://wandb.ai/pykan/KAN_REGRESSION</a><br/>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20240528_211230-izy4wlj6/logs</code>"},"metadata":{}}]}]}