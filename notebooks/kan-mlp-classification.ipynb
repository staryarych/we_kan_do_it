{"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"},"kaggle":{"accelerator":"gpu","dataSources":[],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport math\nimport random\n\nfrom dotenv import load_dotenv, find_dotenv\n\nimport numpy as np\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n\nimport torch\nimport torch.nn as nn\nfrom torch.nn import functional as F\nfrom torchvision.datasets import MNIST\nfrom torch.utils.data import DataLoader\nfrom torchvision import transforms\nimport torch.nn.init as init\n\nimport wandb\n\n__ENV_FILE = find_dotenv(f'{os.getenv(\"ENV\", \"var\")}.env')\nload_dotenv(__ENV_FILE)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def seed_all(seed_value):\n    random.seed(seed_value)\n    np.random.seed(seed_value)\n    torch.manual_seed(seed_value)\n    if torch.cuda.is_available():\n        torch.cuda.manual_seed(seed_value)\n        torch.cuda.manual_seed_all(seed_value)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Models definitions","metadata":{}},{"cell_type":"code","source":"class KANLinear(torch.nn.Module):\n    def __init__(\n        self,\n        in_features,\n        out_features,\n        grid_size=5,\n        spline_order=3,\n        scale_noise=0.1,\n        scale_base=1.0,\n        scale_spline=1.0,\n        enable_standalone_scale_spline=True,\n        base_activation=torch.nn.SiLU,\n        grid_eps=0.02,\n        grid_range=[-1, 1],\n    ):\n        super(KANLinear, self).__init__()\n        self.in_features = in_features\n        self.out_features = out_features\n        self.grid_size = grid_size\n        self.spline_order = spline_order\n\n        h = (grid_range[1] - grid_range[0]) / grid_size\n        grid = (\n            (\n                torch.arange(-spline_order, grid_size + spline_order + 1) * h\n                + grid_range[0]\n            )\n            .expand(in_features, -1)\n            .contiguous()\n        )\n        self.register_buffer(\"grid\", grid)\n\n        self.base_weight = torch.nn.Parameter(torch.Tensor(out_features, in_features))\n        self.spline_weight = torch.nn.Parameter(\n            torch.Tensor(out_features, in_features, grid_size + spline_order)\n        )\n        if enable_standalone_scale_spline:\n            self.spline_scaler = torch.nn.Parameter(\n                torch.Tensor(out_features, in_features)\n            )\n\n        self.scale_noise = scale_noise\n        self.scale_base = scale_base\n        self.scale_spline = scale_spline\n        self.enable_standalone_scale_spline = enable_standalone_scale_spline\n        self.base_activation = base_activation()\n        self.grid_eps = grid_eps\n\n        self.reset_parameters()\n\n    def reset_parameters(self):\n        torch.nn.init.kaiming_uniform_(self.base_weight, a=math.sqrt(5) * self.scale_base)\n        with torch.no_grad():\n            noise = (\n                (\n                    torch.rand(self.grid_size + 1, self.in_features, self.out_features)\n                    - 1 / 2\n                )\n                * self.scale_noise\n                / self.grid_size\n            )\n            self.spline_weight.data.copy_(\n                (self.scale_spline if not self.enable_standalone_scale_spline else 1.0)\n                * self.curve2coeff(\n                    self.grid.T[self.spline_order : -self.spline_order],\n                    noise,\n                )\n            )\n            if self.enable_standalone_scale_spline:\n                # torch.nn.init.constant_(self.spline_scaler, self.scale_spline)\n                torch.nn.init.kaiming_uniform_(self.spline_scaler, a=math.sqrt(5) * self.scale_spline)\n\n    def b_splines(self, x: torch.Tensor):\n        \"\"\"\n        Compute the B-spline bases for the given input tensor.\n\n        Args:\n            x (torch.Tensor): Input tensor of shape (batch_size, in_features).\n\n        Returns:\n            torch.Tensor: B-spline bases tensor of shape (batch_size, in_features, grid_size + spline_order).\n        \"\"\"\n        assert x.dim() == 2 and x.size(1) == self.in_features\n\n        grid: torch.Tensor = (\n            self.grid\n        )  # (in_features, grid_size + 2 * spline_order + 1)\n        x = x.unsqueeze(-1)\n        bases = ((x >= grid[:, :-1]) & (x < grid[:, 1:])).to(x.dtype)\n        for k in range(1, self.spline_order + 1):\n            bases = (\n                (x - grid[:, : -(k + 1)])\n                / (grid[:, k:-1] - grid[:, : -(k + 1)])\n                * bases[:, :, :-1]\n            ) + (\n                (grid[:, k + 1 :] - x)\n                / (grid[:, k + 1 :] - grid[:, 1:(-k)])\n                * bases[:, :, 1:]\n            )\n\n        assert bases.size() == (\n            x.size(0),\n            self.in_features,\n            self.grid_size + self.spline_order,\n        )\n        return bases.contiguous()\n\n    def curve2coeff(self, x: torch.Tensor, y: torch.Tensor):\n        \"\"\"\n        Compute the coefficients of the curve that interpolates the given points.\n\n        Args:\n            x (torch.Tensor): Input tensor of shape (batch_size, in_features).\n            y (torch.Tensor): Output tensor of shape (batch_size, in_features, out_features).\n\n        Returns:\n            torch.Tensor: Coefficients tensor of shape (out_features, in_features, grid_size + spline_order).\n        \"\"\"\n        assert x.dim() == 2 and x.size(1) == self.in_features\n        assert y.size() == (x.size(0), self.in_features, self.out_features)\n\n        A = self.b_splines(x).transpose(\n            0, 1\n        )  # (in_features, batch_size, grid_size + spline_order)\n        B = y.transpose(0, 1)  # (in_features, batch_size, out_features)\n        solution = torch.linalg.lstsq(\n            A, B\n        ).solution  # (in_features, grid_size + spline_order, out_features)\n        result = solution.permute(\n            2, 0, 1\n        )  # (out_features, in_features, grid_size + spline_order)\n\n        assert result.size() == (\n            self.out_features,\n            self.in_features,\n            self.grid_size + self.spline_order,\n        )\n        return result.contiguous()\n\n    @property\n    def scaled_spline_weight(self):\n        return self.spline_weight * (\n            self.spline_scaler.unsqueeze(-1)\n            if self.enable_standalone_scale_spline\n            else 1.0\n        )\n\n    def forward(self, x: torch.Tensor):\n        assert x.size(-1) == self.in_features\n        original_shape = x.shape\n        x = x.view(-1, self.in_features)\n\n        base_output = F.linear(self.base_activation(x), self.base_weight)\n        spline_output = F.linear(\n            self.b_splines(x).view(x.size(0), -1),\n            self.scaled_spline_weight.view(self.out_features, -1),\n        )\n        output = base_output + spline_output\n        \n        output = output.view(*original_shape[:-1], self.out_features)\n        return output\n\n    @torch.no_grad()\n    def update_grid(self, x: torch.Tensor, margin=0.01):\n        assert x.dim() == 2 and x.size(1) == self.in_features\n        batch = x.size(0)\n\n        splines = self.b_splines(x)  # (batch, in, coeff)\n        splines = splines.permute(1, 0, 2)  # (in, batch, coeff)\n        orig_coeff = self.scaled_spline_weight  # (out, in, coeff)\n        orig_coeff = orig_coeff.permute(1, 2, 0)  # (in, coeff, out)\n        unreduced_spline_output = torch.bmm(splines, orig_coeff)  # (in, batch, out)\n        unreduced_spline_output = unreduced_spline_output.permute(\n            1, 0, 2\n        )  # (batch, in, out)\n\n        # sort each channel individually to collect data distribution\n        x_sorted = torch.sort(x, dim=0)[0]\n        grid_adaptive = x_sorted[\n            torch.linspace(\n                0, batch - 1, self.grid_size + 1, dtype=torch.int64, device=x.device\n            )\n        ]\n\n        uniform_step = (x_sorted[-1] - x_sorted[0] + 2 * margin) / self.grid_size\n        grid_uniform = (\n            torch.arange(\n                self.grid_size + 1, dtype=torch.float32, device=x.device\n            ).unsqueeze(1)\n            * uniform_step\n            + x_sorted[0]\n            - margin\n        )\n\n        grid = self.grid_eps * grid_uniform + (1 - self.grid_eps) * grid_adaptive\n        grid = torch.concatenate(\n            [\n                grid[:1]\n                - uniform_step\n                * torch.arange(self.spline_order, 0, -1, device=x.device).unsqueeze(1),\n                grid,\n                grid[-1:]\n                + uniform_step\n                * torch.arange(1, self.spline_order + 1, device=x.device).unsqueeze(1),\n            ],\n            dim=0,\n        )\n\n        self.grid.copy_(grid.T)\n        self.spline_weight.data.copy_(self.curve2coeff(x, unreduced_spline_output))\n\n    def regularization_loss(self, regularize_activation=1.0, regularize_entropy=1.0):\n        \"\"\"\n        Compute the regularization loss.\n\n        This is a dumb simulation of the original L1 regularization as stated in the\n        paper, since the original one requires computing absolutes and entropy from the\n        expanded (batch, in_features, out_features) intermediate tensor, which is hidden\n        behind the F.linear function if we want an memory efficient implementation.\n\n        The L1 regularization is now computed as mean absolute value of the spline\n        weights. The authors implementation also includes this term in addition to the\n        sample-based regularization.\n        \"\"\"\n        l1_fake = self.spline_weight.abs().mean(-1)\n        regularization_loss_activation = l1_fake.sum()\n        p = l1_fake / regularization_loss_activation\n        regularization_loss_entropy = -torch.sum(p * p.log())\n        return (\n            regularize_activation * regularization_loss_activation\n            + regularize_entropy * regularization_loss_entropy\n        )\n\n\nclass KAN(torch.nn.Module):\n    def __init__(\n        self,\n        layers_hidden,\n        grid_size=5,\n        spline_order=3,\n        scale_noise=0.1,\n        scale_base=1.0,\n        scale_spline=1.0,\n        base_activation=torch.nn.SiLU,\n        grid_eps=0.02,\n        grid_range=[-1, 1],\n    ):\n        super(KAN, self).__init__()\n        self.grid_size = grid_size\n        self.spline_order = spline_order\n\n        self.layers = torch.nn.ModuleList()\n        for in_features, out_features in zip(layers_hidden, layers_hidden[1:]):\n            self.layers.append(\n                KANLinear(\n                    in_features,\n                    out_features,\n                    grid_size=grid_size,\n                    spline_order=spline_order,\n                    scale_noise=scale_noise,\n                    scale_base=scale_base,\n                    scale_spline=scale_spline,\n                    base_activation=base_activation,\n                    grid_eps=grid_eps,\n                    grid_range=grid_range,\n                )\n            )\n\n    def forward(self, x: torch.Tensor, update_grid=False):\n        for layer in self.layers:\n            if update_grid:\n                layer.update_grid(x)\n            x = layer(x)\n        return x\n\n    def regularization_loss(self, regularize_activation=1.0, regularize_entropy=1.0):\n        return sum(\n            layer.regularization_loss(regularize_activation, regularize_entropy)\n            for layer in self.layers\n        )","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class MLP(nn.Module):\n    def __init__(self, input_size, hidden_size, output_size):\n        super(MLP, self).__init__()\n        self.fc1 = nn.Linear(input_size, hidden_size)\n        self.relu = nn.ReLU()\n        self.fc2 = nn.Linear(hidden_size, output_size)\n        self.fin = nn.Softmax(dim=1)\n        \n        init.kaiming_uniform_(self.fc1.weight, nonlinearity='relu')\n        init.kaiming_uniform_(self.fc2.weight, nonlinearity='relu')\n\n    def forward(self, x):\n        out = self.fc1(x)\n        out = self.relu(out)\n        out = self.fc2(out)\n        out = self.fin(out)\n        \n        return out","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Trainning","metadata":{}},{"cell_type":"markdown","source":"## Prepare MNIST dataset","metadata":{}},{"cell_type":"code","source":"dataset = MNIST(os.getcwd(), download=True, transform=transforms.ToTensor())\nTRAIN_SPLIT = 0.8\nVALIDATION_SPLIT = 0.1\nTEST_SPLIT = 0.1\nBATCH_SIZE = 4\nseed_all(42)\n\nshallow_dataset= torch.utils.data.Subset(dataset, [i for i in range(500)])\ntrain_set, validation_set, test_set = torch.utils.data.random_split(\n    shallow_dataset, [TRAIN_SPLIT, VALIDATION_SPLIT, TEST_SPLIT]\n)\n\ntrain_loader = DataLoader(train_set, batch_size=BATCH_SIZE)\nvalidation_loader = DataLoader(validation_set, batch_size=BATCH_SIZE)\ntest_loader = DataLoader(test_set, batch_size=BATCH_SIZE)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"INPUT_SIZE = 784\nHIDDEN_SIZE = 128\nOUTPUT_SIZE = 10\nNUM_EPOCHS = 3\nLEARNING_RATE = 1E-3\nDEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## MLP","metadata":{}},{"cell_type":"code","source":"# wandb config\n\n# WANDB_API_KEY = os.environ.get('WANDB_API_KEY')\nWANDB_API_KEY=\"5b2ceb8edc2e4f40870207591750b6a38db675fc\"\nwandb.login(key=WANDB_API_KEY)\n\nrun = wandb.init(\n    project=\"MLP_CLASSIFICATION\",\n    config={\n        \"learning_rate\": LEARNING_RATE,\n        \"epochs\": NUM_EPOCHS,\n        \"entity\": \"staff\",\n        \"group\": \"creating_kan\",\n        \"name\": \"CUM\",\n    },\n)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = MLP(INPUT_SIZE, HIDDEN_SIZE, OUTPUT_SIZE)\nmodel = model.to(DEVICE)\n\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n\nwandb.watch(model, log=\"all\")\nwandb.log({'M_parameters': sum(p.numel() for p in model.parameters())/1e6})\nfor epoch in range(NUM_EPOCHS):\n    model.train()\n    for inputs, labels in train_loader:\n        inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n        \n        inputs = inputs.view(inputs.shape[0], -1)\n        logits = model(inputs)\n        pred_label = torch.argmax(logits, dim=1)\n        loss = criterion(logits, labels)\n        \n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n        wandb.log({\"train_loss\": loss})\n\n    # validation\n    model.eval()\n    ep_accs, ep_precs, ep_recs , ep_f1s = torch.zeros(1),  torch.zeros(1), torch.zeros(1), torch.zeros(1)\n    \n    for inputs, labels in validation_loader:        \n        inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n        \n        inputs = inputs.view(inputs.shape[0], -1)\n        logits = model(inputs)\n        pred_labels = torch.argmax(logits, dim=1)\n        \n        y_true = labels.detach().cpu().numpy()\n        y_pred = pred_labels.detach().cpu().numpy()\n        \n        accuracy = accuracy_score(y_true, y_pred)\n        precision = precision_score(y_true, y_pred, average='macro', zero_division=0.0)\n        recall = recall_score(y_true, y_pred, average='macro', zero_division=0.0)\n        f1 = f1_score(y_true, y_pred, average='macro', zero_division=0.0)\n        \n        ep_accs += accuracy\n        ep_precs += precision\n        ep_recs += recall\n        ep_f1s += f1\n        \n    ep_accs /= len(validation_loader)\n    ep_precs /= len(validation_loader)\n    ep_recs /= len(validation_loader)\n    ep_f1s /= len(validation_loader)\n    \n    wandb.log({\"validation_accuracy\": ep_accs})\n    wandb.log({\"validation_precision\": ep_precs})\n    wandb.log({\"validation_recall\": ep_recs})\n    wandb.log({\"validation_f1\": ep_f1s})\n            \nmodel.eval()\nfor epoch in range(1):\n    ep_accs, ep_precs, ep_recs , ep_f1s = torch.zeros(1),  torch.zeros(1), torch.zeros(1), torch.zeros(1)\n    \n    for inputs, labels in test_loader:        \n        inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n        \n        inputs = inputs.view(inputs.shape[0], -1)\n        logits = model(inputs)\n        pred_labels = torch.argmax(logits, dim=1)\n        \n        y_true = labels.detach().cpu().numpy()\n        y_pred = pred_labels.detach().cpu().numpy()\n        \n        accuracy = accuracy_score(y_true, y_pred)\n        precision = precision_score(y_true, y_pred, average='macro', zero_division=0.0)\n        recall = recall_score(y_true, y_pred, average='macro', zero_division=0.0)\n        f1 = f1_score(y_true, y_pred, average='macro', zero_division=0.0)\n\n        ep_accs += accuracy\n        ep_precs += precision\n        ep_recs += recall\n        ep_f1s += f1\n    \n    ep_accs /= len(test_loader)\n    ep_precs /= len(test_loader)\n    ep_recs /= len(test_loader)\n    ep_f1s /= len(test_loader)\n    \n    wandb.log({\"test_accuracy\": ep_accs})\n    wandb.log({\"test_precision\": ep_precs})\n    wandb.log({\"test_recall\": ep_recs})\n    wandb.log({\"test_f1\": ep_f1s})\n        \nwandb.finish()","metadata":{"scrolled":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# KAN","metadata":{}},{"cell_type":"code","source":"# wandb config\n\n# WANDB_API_KEY = os.environ.get('WANDB_API_KEY')\nWANDB_API_KEY=\"5b2ceb8edc2e4f40870207591750b6a38db675fc\"\nwandb.login(key=WANDB_API_KEY)\n\nrun = wandb.init(\n    project=\"KAN_CLASSIFICATION\",\n    config={\n        \"learning_rate\": LEARNING_RATE,\n        \"epochs\": NUM_EPOCHS,\n        \"entity\": \"staff\",\n        \"group\": \"creating_kan\",\n        \"name\": \"KAN\",\n    },\n)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = KAN([INPUT_SIZE,OUTPUT_SIZE])\nmodel = model.to(DEVICE)\n\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n\n\nwandb.watch(model, log=\"all\")\nwandb.log({'M_parameters': sum(p.numel() for p in model.parameters())/1e6})\nfor epoch in range(NUM_EPOCHS):\n    model.train()\n    for inputs, labels in train_loader:\n        \n        inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n        \n        inputs = inputs.view(inputs.shape[0], -1)\n        logits = model(inputs)\n        loss = criterion(logits, labels)\n        \n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n        \n        wandb.log({\"train_loss\": loss})\n\n    # validation\n    model.eval()\n    ep_accs, ep_precs, ep_recs , ep_f1s = torch.zeros(1),  torch.zeros(1), torch.zeros(1), torch.zeros(1)\n    \n    for inputs, labels in validation_loader:        \n        inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n        \n        inputs = inputs.view(inputs.shape[0], -1)\n        logits = model(inputs)\n        pred_labels = torch.argmax(logits, dim=1)\n        \n        y_true = labels.detach().cpu().numpy()\n        y_pred = pred_labels.detach().cpu().numpy()\n        \n        accuracy = accuracy_score(y_true, y_pred)\n        precision = precision_score(y_true, y_pred, average='macro', zero_division=0.0)\n        recall = recall_score(y_true, y_pred, average='macro', zero_division=0.0)\n        f1 = f1_score(y_true, y_pred, average='macro', zero_division=0.0)\n        \n        ep_accs += accuracy\n        ep_precs += precision\n        ep_recs += recall\n        ep_f1s += f1\n        \n    ep_accs /= len(validation_loader)\n    ep_precs /= len(validation_loader)\n    ep_recs /= len(validation_loader)\n    ep_f1s /= len(validation_loader)\n    \n    wandb.log({\"validation_accuracy\": ep_accs})\n    wandb.log({\"validation_precision\": ep_precs})\n    wandb.log({\"validation_recall\": ep_recs})\n    wandb.log({\"validation_f1\": ep_f1s})\n\n\n\n# test\nmodel.eval()\nfor epoch in range(1):\n    ep_accs, ep_precs, ep_recs , ep_f1s = torch.zeros(1),  torch.zeros(1), torch.zeros(1), torch.zeros(1)\n    \n    for inputs, labels in test_loader:        \n        inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n        \n        inputs = inputs.view(inputs.shape[0], -1)\n        logits = model(inputs)\n        pred_labels = torch.argmax(logits, dim=1)\n        \n        y_true = labels.detach().cpu().numpy()\n        y_pred = pred_labels.detach().cpu().numpy()\n        \n        accuracy = accuracy_score(y_true, y_pred)\n        precision = precision_score(y_true, y_pred, average='macro', zero_division=0.0)\n        recall = recall_score(y_true, y_pred, average='macro', zero_division=0.0)\n        f1 = f1_score(y_true, y_pred, average='macro', zero_division=0.0)\n        \n        ep_accs += accuracy\n        ep_precs += precision\n        ep_recs += recall\n        ep_f1s += f1\n\n    ep_accs /= len(test_loader)\n    ep_precs /= len(test_loader)\n    ep_recs /= len(test_loader)\n    ep_f1s /= len(test_loader)\n    \n    wandb.log({\"test_accuracy\": ep_accs})\n    wandb.log({\"test_precision\": ep_precs})\n    wandb.log({\"test_recall\": ep_recs})\n    wandb.log({\"test_f1\": ep_f1s})\n        \nwandb.finish()","metadata":{},"execution_count":null,"outputs":[]}]}